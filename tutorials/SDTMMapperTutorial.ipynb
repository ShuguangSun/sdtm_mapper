{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on how to use SDTMMapper to generate mapping specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will cover how to generate mapping specifications for your datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import backend as K\n",
    "import keras.layers as layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Flatten\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical, np_utils\n",
    "from keras.engine import Layer\n",
    "#from keras.esimator import model_to_estimator\n",
    "import numpy as np\n",
    "\n",
    "from SDTMMapper import SDTMMapper, SDTMModels\n",
    "bucket='snvn-sagemaker-1' #data bucket\n",
    "KEY='mldata/Sam/data/project/380-000/bipolar/380-201/csr/data/raw/latest/'\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load SDTMMapper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Load `SDTMMapper` utilities\n",
    "\n",
    "2 Load SAS datasets from s3 to try a model on new data. If your datasets are in local, then sent `s3=False`.\n",
    "\n",
    "`SDTMMapper(domain, isS3, bucket='', KEY='', localpath='',**kwargs)`\n",
    "\n",
    "- `domain` - name of the dataset e.g. ae\n",
    "- `isS3` - is the datasets on s3?\n",
    "- `bucket` -  s3 specific\n",
    "- `KEY` - s3 specific\n",
    "- `localpath` - the directory path to the folder containing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdtmmap=SDTMMapper.SDTMMapper('ae', True, bucket, KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load SDTMModels\n",
    "\n",
    "1. Specify domain name and the model you want to use. \n",
    "2. For this tutorial, I will use `model 3`: `Elmo+fnn+ae+Model3.h5`. Set the size of softmax layer to `34`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "models = SDTMModels.SDTMModels('ae', 34)\n",
    "model = models.build_model(3, False)\n",
    "model.load_weights('../model/Elmo+fnn+ae+Model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Mapping Spec Template in CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, SAS variable names and variable labels are extracted and stored in a csv file.\n",
    "\n",
    "The CSV file will be stored in `test_data` folder. If the folder does not exist, it will create for you.\n",
    "\n",
    "You need to specify the encoding of your SAS dataset, and the file name of the output CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae=sdtmmap.sas_metadata_to_csv('latin','test_study_ae.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can hard code what raw variables should be dropped with regular expressionin `suffix`.\n",
    "\n",
    "You need to specify what EDC system was used for your raw SAS dataset. Here I am specifying as 'rave'. Currently this is the only EDC system supported.\n",
    "\n",
    "`drop_sys_vars` generates three outputs. \n",
    "\n",
    "1. A Pandas dataframe containing dropping variables,\n",
    "2. A Pandas Series of variable metadata excluding dropping variables.\n",
    "3. A Pandas dataframe of variable metadata excluding dropping variables.\n",
    "\n",
    "All letters will be also converted to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables to be dropped with these suffic\n",
    "suffix='.*_RAW$|.*_INT$|.*_STD$|.*_D{1,2}$|.*_M{1,2}$|.*_Y{1,4}$' \n",
    "\n",
    "Dt, Xt, df=sdtmmap.drop_sys_vars(os.path.join('test_data','test_study_ae.csv'), 'rave',suffix) \n",
    "X=np.array(Xt, dtype=object)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>sdtm</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROJECTID</td>\n",
       "      <td>PROJECTID projectid</td>\n",
       "      <td>DROP</td>\n",
       "      <td>DROP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROJECT</td>\n",
       "      <td>PROJECT project</td>\n",
       "      <td>DROP</td>\n",
       "      <td>DROP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STUDYID</td>\n",
       "      <td>STUDYID Internal id for the study</td>\n",
       "      <td>DROP</td>\n",
       "      <td>DROP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENVIRONMENTNAME</td>\n",
       "      <td>ENVIRONMENTNAME Environment</td>\n",
       "      <td>DROP</td>\n",
       "      <td>DROP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBJECTID</td>\n",
       "      <td>SUBJECTID Internal id for the subject</td>\n",
       "      <td>DROP</td>\n",
       "      <td>DROP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                   text  sdtm  pred\n",
       "0        PROJECTID                    PROJECTID projectid  DROP  DROP\n",
       "1          PROJECT                        PROJECT project  DROP  DROP\n",
       "2          STUDYID      STUDYID Internal id for the study  DROP  DROP\n",
       "3  ENVIRONMENTNAME            ENVIRONMENTNAME Environment  DROP  DROP\n",
       "4        SUBJECTID  SUBJECTID Internal id for the subject  DROP  DROP"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sdtm']=sdtmmap.decode_sdtm_target(output)\n",
    "spec=sdtmmap.add_drop(df,Dt.iloc[:,:3:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
